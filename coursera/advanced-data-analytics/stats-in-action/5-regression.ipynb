{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b15c29e7-dd42-4cb0-b1a2-be8ded75a68c",
   "metadata": {},
   "source": [
    "# Regression\n",
    "\n",
    "- Assumptions of the given regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b6a847-9fb1-4ed5-b362-9fc48a651993",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d2d6e6a5-5aba-419f-9d86-fdf021179bbb",
   "metadata": {},
   "source": [
    "## Linear Regression\n",
    "\n",
    "### Assumptions\n",
    "\n",
    "- **Linearity**\n",
    "  - Linear relationship between Predictor variables (`X`) and Outcome variables (`y`)\n",
    "  - Check by **Scatter plot** with Predictor variables and Outcome variable B\n",
    "    - `sns.pairplot` to plot multiple pair between multiple variables\n",
    "  - NOTE: If violated, try\n",
    "    - Take the logarithm to transform data (or other transformations)\n",
    "- **Independent Observations**\n",
    "  - Observations are independent to each other, i.e. each data entry is independent to each other\n",
    "  - Check data collection process\n",
    "  - NOTE: If violated, try\n",
    "    - Take just a subset of the available data\n",
    "- **Normality**\n",
    "  - <mark>Errors (Residuals) are normally distributed</mark>\n",
    "    - I.e. difference between observed and predicted for each data point is normally distributed\n",
    "    - Errors: the _natural noises_ assumed to be in the model\n",
    "    - Residuals: the _difference_ between predicted and observed values\n",
    "      - Calculated after building the model\n",
    "  - Check by **Histogram plot** of residuals\n",
    "  - Check by **Q-Q plot** between the residuals and Normal Distribution\n",
    "    - After model is constructed, get their residuals `model.resid`\n",
    "    - Then, import the modules `import statsmodels.api as sm`\n",
    "    - Then, plot Quartile-Quartile plot by `sm.qqplot(model.resid, line='s')`\n",
    "  - NOTE: If violated, try\n",
    "    - Take the logarithm on dependent variable (y) or X\n",
    "- **Homoscedasticity**\n",
    "  - <mark>Residuals have constant or similar variance across the model</mark>\n",
    "    - I.e. the difference between observed and predicted is within a similar range\n",
    "  - Check by residual plots\n",
    "    - I.e. **Scatter plot** between residuals and fitted values (i.e. predicted values)\n",
    "  - NOTE: If violated, try\n",
    "    - Define a different dependent variable\n",
    "    - Transform the Y variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567227df-85e3-45fc-880d-ec0213b90be2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f0716fa7-6919-431d-8ca2-ded3c1b4e7fc",
   "metadata": {},
   "source": [
    "## Multiple Linear Regression\n",
    "\n",
    "### Assumptions\n",
    "\n",
    "- **Linearity**\n",
    "  - Each independent variable (X) is linearly related to the dependent variable (y)\n",
    "    - Independent = Predictor, Dependent = Outcome\n",
    "  - Check by:\n",
    "    - Scatter plot between each X and y, expect somewhat linear relationship between them\n",
    "      - E.g. `sns.pairplot`\n",
    "- **Independent observations**\n",
    "  - Each observation in the dataset is independent to each other\n",
    "  - Check by:\n",
    "    - Review the data collection process\n",
    "- **<mark>(Multivariate) normality</mark>**\n",
    "  - Errors (Residuals) are normally distributed\n",
    "    - I.e. the difference between predicted and observed values are normally distributed\n",
    "  - Check by Q-Q Plot, between Model Residuals and Normal Distribution\n",
    "    - Expect plot shows a diagonal line of around 45 degrees\n",
    "  - Check by Histogram of the Residuals, if is close to Normal DistributionN\n",
    "    - Expect to be like Normal Distribution\n",
    "- **Homoscedasticity**\n",
    "  - Variation of the errors is constant or similar across the model\n",
    "  - Check by Residual plot:\n",
    "    - I.e. Scatter plot between residuals and predicted values \n",
    "      - Expect the variation on Y-axis within a constant/similar range across whole X-axis\n",
    "- **<mark>No multicollinearity</mark>**\n",
    "  - <mark>Any of the two independent variables (X) are NOT highly correlated with each other</mark>\n",
    "  - Check by **Scatter plot** between X variables\n",
    "      - Expect NO straight line pattern\n",
    "  - Check by **Variance Inflation Factors (VIF)**\n",
    "    - Quantify how much the variance of each variable is \"inflated\" due to correlation with other X variables\n",
    "    - `from statsmodels.stats.outliers_influence import variance_inflation_factor`\n",
    "    - VIF = 1 => No Correlation\n",
    "  - NOTE: If violated, try\n",
    "    - Keep only one of the correlated variables\n",
    "      - **Forward Selection**\n",
    "        - Begins with null model (0 independent variable)\n",
    "      - **Backward Elimination**\n",
    "        - Begins with full model (all of the independent variables)\n",
    "    - **Lasso Regression** (Regularization)\n",
    "      - Completely remove the X variables that are not important in predicting y\n",
    "      - NOTE: <font color='blue'>Lasso AS \"套索\", so non-relevant variables are looped and removed from the equation!</font>\n",
    "    - **Ridge Regression** (Regularization)\n",
    "      - Minimize the impact from X variables that are not important\n",
    "      - Not removing any X variable\n",
    "    - Principal component analysis (PCA)\n",
    "\n",
    "### Interpretations\n",
    "\n",
    "> Results from `statsmodels.api`\n",
    "\n",
    "- Coefficients `p-values` (for each coefficient)\n",
    "  - Hypotheses\n",
    "    - Null: coefficient = 0\n",
    "    - Alternative: coefficient != 0\n",
    "  - If `p-value` < significance level, reject the null hypothesis\n",
    "    - The coefficient is statistically significant\n",
    "    - The given X (independent) is correlated to y (dependent)\n",
    "- Coefficients `Confidence Intervals`\n",
    "  - With 95% Confidence Interval\n",
    "    - the interval has a 95% chance of containing the true parameter value of the coefficient\n",
    "    - if you were to repeat this experiment many times, 95% of the confidence intervals would contain the true value\n",
    "  - Confidence Band\n",
    "    - the line that describes the uncertainty around the predicted outcome"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a646a835-9a08-455d-8468-ab0d72934fc4",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "\n",
    "### Assumptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cdd03da-c9a2-4c0b-9653-f3405315b354",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13850f6e-fcab-42db-8369-2bd9c2a649e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0f57da81-1e9f-44c6-bf41-b953e01e32bf",
   "metadata": {},
   "source": [
    "## Model Evaluations\n",
    "\n",
    "- **R², R-Squared**\n",
    "  - **Coefficient of Determination**, value between 0 and 1; the higher the better\n",
    "  - **Proportion of variation in `y` that is explained by `X`** (all of X variables)\n",
    "  - To get better model explanations: proportion of variation that is explained\n",
    "  - Formula\n",
    "    - `1 - Unexplained Variation`\n",
    "    - Unexplained Variation = \n",
    "      - `(Sum of Squared Residuals)`, divided by `Total Sum of Squares`\n",
    "  - Issues\n",
    "    - With more X variables, difficult to tell which contributes to the explained variations\n",
    "    - Higher R-Squared might happen due to over-fitting\n",
    "- **Adjusted R²**\n",
    "  - R-Squared but **penalises unnecessary explanatory variable**\n",
    "  - To compare models of varying complexity\n",
    "    - By adding or removing a variable, and then compare the Adjusted-R²\n",
    "  - Between 0 and 1\n",
    "- **MAE**, Mean Absolute Error\n",
    "  - Average of the absolute difference between the observed and predicted values\n",
    "  - Good to use with data having outliers that should be excluded/ignored in evaluation\n",
    "  - _Not too sensitive to large errors_\n",
    "- **MSE**, Mean Squared Error\n",
    "  - Average of the squared difference between the observed and predicted values\n",
    "  - Sensitive to large errors, because the differences are _squared_\n",
    "- **AIC (Akaike information criterion)**\n",
    "  - https://machinelearningmastery.com/probabilistic-model-selection-measures/\n",
    "  - ...\n",
    "- **BIC (Bayesian information criterion)**\n",
    "  - ...\n",
    "- **Bias & Variance trade-off**\n",
    "  - **High Bias: under-fit with the sample data**\n",
    "    - Over-simplify the variable relationships by making assumptions\n",
    "    - <mark>NOTE: Bias-Under</mark>, more bias leads to more under-fitting\n",
    "    - NOTE: Simply saying `y = 2` is a \"High Bias (under-fitting)\" model\n",
    "  - **High Variance: over-fit with the sample data**\n",
    "    - NOTE: Variance-Over\n",
    "    - Learned from existing data and incorporate flexibility and complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e262e29-09be-430e-963b-84f14d0af80a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7f4a855e-e2d3-40e1-b533-c39f85e48614",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "- [Underfitting and overfitting](https://www.coursera.org/learn/regression-analysis-simplify-complex-data-relationships/supplement/jtFae/underfitting-and-overfitting)\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284c9ff0-dccd-4f15-bc5c-dca6774b4fe1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
